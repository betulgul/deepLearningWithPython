{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import datasets\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") # select the device to be cuda, in order to speed up the process\nprint('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:00:19.819737Z","iopub.execute_input":"2021-08-16T18:00:19.820127Z","iopub.status.idle":"2021-08-16T18:00:21.182462Z","shell.execute_reply.started":"2021-08-16T18:00:19.820048Z","shell.execute_reply":"2021-08-16T18:00:21.181607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([\n            transforms.ToTensor(),\n            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),])\n\ntransform_val = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n])\n\n\n\n\ntrainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform) # Data augmentation is only done on training images\nvalset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_val)\n\n\ntrainloader = torch.utils.data.DataLoader(\n    trainset,\n    batch_size=4,\n    shuffle=True,\n    num_workers=100 )# load the dataset with 16 batch size and suffle the dataset\nvalloader = torch.utils.data.DataLoader(\n    valset,\n    batch_size=1,\n    num_workers=100 )# load the dataset with 16 batch size and suffle the dataset\nprint(len(valset))\nprint(len(trainset))","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:00:21.184171Z","iopub.execute_input":"2021-08-16T18:00:21.184786Z","iopub.status.idle":"2021-08-16T18:00:29.991633Z","shell.execute_reply.started":"2021-08-16T18:00:21.184747Z","shell.execute_reply":"2021-08-16T18:00:29.990816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=6,kernel_size=5, stride=1, padding=0)\n        self.pool = nn.AvgPool2d(2,2)\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1, padding=0)\n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n        self.ReLU = nn.ReLU()\n    def forward(self, x):\n        x = self.pool(self.ReLU(self.conv1(x))) # conv1 -> ReLU -> maxpool -> conv2 -> ReLU -> maxpool -> conv3 -ReLU -> maxpool\n        x = self.pool(self.ReLU(self.conv2(x)))\n        x = x.view(-1, 16 * 5 * 5)\n        x = self.ReLU(self.fc1(x))\n        x = self.ReLU(self.fc2(x))\n        x = self.fc3(x)\n        return x\n\nnet = Net()\nin1 = torch.ones(16,3,32,32)\n\nout = net(in1)\n\nnet.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:00:29.993473Z","iopub.execute_input":"2021-08-16T18:00:29.99382Z","iopub.status.idle":"2021-08-16T18:00:34.32007Z","shell.execute_reply.started":"2021-08-16T18:00:29.993783Z","shell.execute_reply":"2021-08-16T18:00:34.319324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.AdamW(net.parameters())","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:00:34.321528Z","iopub.execute_input":"2021-08-16T18:00:34.32187Z","iopub.status.idle":"2021-08-16T18:00:34.327831Z","shell.execute_reply.started":"2021-08-16T18:00:34.321835Z","shell.execute_reply":"2021-08-16T18:00:34.327123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install livelossplot==0.1.2 # command to install livelossplot","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:00:34.328859Z","iopub.execute_input":"2021-08-16T18:00:34.329194Z","iopub.status.idle":"2021-08-16T18:00:43.421142Z","shell.execute_reply.started":"2021-08-16T18:00:34.329161Z","shell.execute_reply":"2021-08-16T18:00:43.420228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch, time, copy, sys, os\nimport matplotlib.pyplot as plt\nfrom livelossplot import PlotLosses\nimport torch.optim.lr_scheduler as lr_scheduler\nimport math\n\nliveloss = PlotLosses() # to plot loss and accuracy\n\nepochs = 10 # number of epochs\n\nlf = lambda x: (((1 + math.cos(x * math.pi / epochs)) / 2) ** 1.0) * 0.95 + 0.05  # cosine schedule\n# scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.6) # ReduceLROnPlateau scheduler\nscheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lf) # LambdaLR scheduler\n\nprint(\"starting\")\nbest_acc = 0.0 #best accuracy\nfor epoch in range(epochs):  # loop over the dataset multiple times for training\n    print(\"epoch: \", epoch)\n    running_loss1 = 0.0 # running training loss\n    running_loss2 = 0.0 # running validation loss\n    running_corrects1 = 0 # running training corrects\n    running_corrects2 = 0 # running validation corrects\n    \n    for i, data in enumerate(trainloader, 0):\n#         print(\"iteration: \", i)\n        inputs, labels = data # get the input images and labels\n        inputs, labels = inputs.to(device), labels.to(device) # push the inputs and images to CUDA\n        \n        optimizer.zero_grad() # zero the parameter gradients\n        \n        outputs = net(inputs) # forward pass\n        _, preds = torch.max(outputs, 1) # predicting the outputs\n#         print(\"out: \", outputs.shape, \"labels: \", labels.shape)\n        loss = criterion(outputs, labels) # calculating the loss\n        loss.backward() # backward\n        optimizer.step() # optimizer step\n        \n        running_loss1 += loss.item() # summing each loss of data\n        running_corrects1 += torch.sum(preds == labels.data) # summing each corrects of data\n    \n    tr_loss = running_loss1 / len(trainset) # calculating the average training loss\n    tr_acc = running_corrects1.double() / len(trainset) # calculating the average training accuracy\n    \n    for i, data in enumerate(valloader, 0): # loop over the dataset multiple times for validation\n\n        inputs, labels = data # get the input images and labels\n        inputs, labels = inputs.to(device), labels.to(device) # push the inputs and images to CUDA\n        \n        optimizer.zero_grad() # zero the parameter gradients\n        \n        outputs = net(inputs) # forward pass\n        _, preds = torch.max(outputs, 1) # predicting the outputs\n        loss = criterion(outputs, labels) # calculating the loss\n        running_loss2 += loss.item() # summing each loss of data\n        running_corrects2 += torch.sum(preds == labels.data) # summing each corrects of data\n    \n    val_loss = running_loss2 / len(valset) # calculating the average validation loss\n    val_acc = running_corrects2.double() / len(valset) # calculating the average validation accuracy\n    if val_acc > best_acc: #early pass\n        best_acc = val_acc\n#         best_model = copy.deepcopy(net.state_dict()) #deepcopy of the model if the model reaches its maximum accuracy\n    \n    scheduler.step() # step of learning rate scheduler, if validation loss is not decreasing, the learning rate will be decreased.\n    liveloss.update({  #update the liveloss plot\n    'loss': tr_loss,\n    'val_loss': val_loss,\n    'accuracy': tr_acc,\n    'val_accuracy': val_acc\n    })\n    \n    liveloss.draw() #draw the results\n    print(\"epoch: \", epoch, \"train loss: \", tr_loss, \"val loss: \", val_loss, \"train acc: \", tr_acc.item(), \"val acc: \", val_acc.item(), \"best accuracy: \", best_acc.item()) # printing the results\n    #print( \"train loss: \", tr_loss,\"accuracy\", tr_acc)\n    print()\n    \nprint('Finished Training')","metadata":{"execution":{"iopub.status.busy":"2021-08-16T18:00:43.422743Z","iopub.execute_input":"2021-08-16T18:00:43.42308Z"},"trusted":true},"execution_count":null,"outputs":[]}]}